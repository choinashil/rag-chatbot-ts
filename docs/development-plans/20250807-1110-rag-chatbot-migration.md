# RAG 챗봇 기능 이주 개발 계획서

> **작성일**: 2025-08-07 11:10  
> **대상**: rag-chatbot → rag-chatbot-2 기능 이주  
> **목적**: Express.js 기반에서 Fastify + TypeScript 기반으로 안전한 마이그레이션  

## 개요

기존 rag-chatbot의 기능들을 새로운 Fastify + TypeScript 환경으로 단계적으로 이주하는 개발 계획입니다. 각 단계별로 테스트와 검증을 거쳐 안정적인 기능 이전을 목표로 합니다.

## 마이그레이션 전략

### 기본 원칙
- **점진적 이주**: 한 번에 하나의 기능만 추가
- **단계별 검증**: 각 단계마다 기능 테스트 수행
- **안정성 우선**: REST API → WebSocket 순으로 점진적 개선
- **타입 안전성**: TypeScript 타입 정의 선행

### 작업 방식
- **구조 우선**: 각 단계 시작 전 관련 타입 정의 및 서비스 클래스 구조 먼저 생성
- **필요한 것만**: 해당 단계에 필요한 폴더/파일만 선택적 생성 (전체 구조 미리 생성 금지)
- **단계별 완성도**: 각 단계의 기본 구조 → 실제 구현 → 테스트 → 다음 단계 진행
- **문서화 병행**: 주요 변경사항은 즉시 문서 업데이트

### 기술 스택 변화
| 구분 | 기존 (rag-chatbot) | 신규 (rag-chatbot-2) |
|------|-------------------|----------------------|
| **프레임워크** | Express.js | Fastify |
| **언어** | JavaScript | TypeScript |
| **실시간 통신** | 없음 | WebSocket (Socket.io) |
| **아키텍처** | 단순 구조 | 레이어드 아키텍처 |

## 상세 개발 단계

### 1단계: 기초 구조 구축 🏗️
**예상 소요시간**: 1-2시간  
**목표**: 노션 연동을 위한 기본 타입 및 구조 정의

#### 작업 내용 (완료)
- [x] **기본 타입 정의**
  - `ApiResponse`, `ServiceStatus`, `HealthStatus` 등 공통 타입
  - `Document`, `DocumentSource`, `DocumentMetadata` 문서 타입
  - `NotionConfig`, `NotionPage`, `NotionQueryResult` 노션 타입

- [x] **노션 서비스 클래스 구조 생성**
  - `NotionService` 클래스 스켈레톤 (초기화, 상태 확인 메서드 포함)
  - `NotionMapper` 데이터 변환 클래스 (노션 → Document 변환)
  - `notion.constants.ts` 노션 관련 상수 정의

- [x] **폴더 구조 생성**
  - 필요한 폴더만 선택적 생성 (`types/`, `services/notion/`)
  - 각 폴더별 index.ts 파일로 export 구조 설정

#### 완료 기준 (달성)
- ✅ 노션 관련 모든 타입 정의 완료, 컴파일 에러 없음
- ✅ NotionService 클래스 기본 구조 생성 완료
- ✅ 타입 안전성 확보 (exactOptionalPropertyTypes 호환)

---

### 2단계: 노션 데이터베이스 연동 📚 ✅ COMPLETED
**예상 소요시간**: 2-3시간  
**목표**: 노션에서 문서 데이터 읽기 기능

#### 작업 내용
- [x] **테스트 환경 설정**
  - `.env.test` 파일 생성 및 환경변수 설정
  - Jest 테스트 프레임워크 구성 및 최적화
  - NotionService 단위 테스트 작성 및 모킹

- [x] **노션 서비스 기본 구조**
  - NotionService 클래스 생성자 및 초기화 메서드
  - 연결 상태 확인 및 헬스체크 연동
  - 기본 에러 핸들링 구조

- [x] **노션 API 연동 구현** ✅
  - `getPages()` 메서드: 데이터베이스 쿼리 기능 구현
  - `getPageContent()` 메서드: 페이지 내용 읽기 구현  
  - `queryDatabase()` 메서드: 필터링된 쿼리 기능

- [x] **데이터 변환 로직** ✅
  - Notion 블록 → 마크다운 변환 기본 구현
  - 문서 메타데이터 추출 (제목, 수정일, URL 등)
  - `NotionPage` 타입으로 정규화

- [x] **에러 핸들링**
  - API 호출 실패 처리 구조
  - 타임아웃 및 재시도 로직 기본 구조
  - 테스트를 통한 에러 시나리오 검증

#### 완료 기준 (모두 달성 ✅)
- [x] 헬스체크에서 노션 연결 상태 확인 가능
- [x] 노션 데이터베이스에서 문서 목록 조회 가능
- [x] 개별 문서 내용을 마크다운으로 변환 가능

#### 구현 완료 사항
- **NotionService 메서드 구현**: `getPages(filter?)`, `getPage(pageId)` 실제 로직 완료
- **메서드 통합 및 개선**: 
  - `getPages()` + `queryDatabase()` → `getPages(filter?)` 통합
  - `getPageContent()` → `getPage()` 네이밍 개선
  - 매직 넘버를 상수로 대체 (`MAX_NOTION_PAGE_SIZE`)
- **관심사 분리**: 
  - 데이터 변환 로직을 `NotionMapper`로 완전 이동
  - 블록 타입 상수 활용 (`NOTION_BLOCK_TYPES`)
- **타입 중복 제거**: `NotionPage.title`과 `properties.title` 중복 해결
- **기본 마크다운 변환**: 제목, 문단, 리스트 등 주요 블록 타입 지원
- **에러 처리**: API 호출 실패, 타입 안전성, 로깅 완료
- **포괄적 테스트 구현**: ✅
  - **NotionService 테스트**: 43개 테스트 케이스 (정상/에러 케이스 포함)
  - **NotionMapper 테스트**: 모든 유틸리티 메서드 검증
  - **테스트 커버리지**: NotionService/NotionMapper 99%+ 달성
  - **실행 속도**: 0.7초 내 완료 (개발 흐름 방해 없음)

---

### 3단계: OpenAI 임베딩 연동 📊
**예상 소요시간**: 1-1.5시간  
**목표**: 텍스트를 벡터 임베딩으로 변환하는 기능 구현

#### 세부 단계
##### 3-1단계: OpenAI 기본 설정 및 연결 (30-45분) ✅ COMPLETED
- [x] **OpenAI 패키지 설치 및 환경변수 설정**
  - `openai` 패키지 설치 완료
  - `OPENAI_API_KEY` 환경변수 추가 완료
  - API 키 유효성 검증 로직 구현

- [x] **설정 및 클라이언트 구조**
  - `OpenAIConfig` 타입 정의 완료
  - `createOpenAIConfig()` 함수 구현 완료
  - 기본 OpenAI 클라이언트 초기화 완료
  - 헬스체크에 OpenAI 연결 상태 추가 완료

- [x] **추가 완료 사항**
  - 의사결정 문서 2개 작성 (설정 관리 전략, 임베딩 모델 선택)
  - 개념 설명 문서 작성 (임베딩과 벡터 검색)
  - 통합 테스트 스크립트 작성 (`test-openai-integration.ts`)
  - 포괄적 단위 테스트 작성 (설정 18개 + 클라이언트 21개 테스트)
  - TypeScript 타입 에러 해결 (Node.js, Jest 타입)

##### 3-2단계: 임베딩 서비스 구현 (45-60분) ✅ COMPLETED
- [x] **EmbeddingService 클래스 생성**
  - 텍스트 → 벡터 임베딩 변환 기본 기능 완료
  - `text-embedding-3-small` 모델 사용
  - 토큰 제한 처리 (8191 토큰 제한)
  - 배치 처리, 긴 텍스트 청킹 최적화 완료

- [x] **에러 처리 및 최적화**
  - API 호출 실패 재시도 로직 완료 (지수 백오프)
  - tiktoken 기반 정확한 토큰 계산 및 텍스트 분할
  - 로깅 및 사용량 추적 완료
  - FIFO 캐싱으로 성능 최적화

- [x] **단위 테스트 작성**
  - 20+ 테스트 케이스 완료 (정상/에러/경계값 모든 시나리오)
  - 성능 최적화로 실행시간 9초 → 1.5초 단축 (83% 개선)
  - 캐싱, 배치 처리, 청킹, 사용량 추적 모든 기능 검증

#### 완료 기준 (모두 달성 ✅)
- [x] OpenAI API 연결 및 인증 성공 ✅
- [x] 텍스트를 1536차원 벡터로 변환 가능 ✅
- [x] 헬스체크에서 OpenAI 상태 확인 가능 ✅
- [x] 단위 테스트 통과 ✅

#### 3-1단계 구현 완료 사항 ✅
- **패키지 및 환경 설정**: OpenAI 패키지 설치, 환경변수 구성 완료
- **타입 시스템**: `OpenAIConfig`, `OpenAIServiceStatus` 등 모든 필요 타입 정의
- **설정 관리**: 환경변수+상수 조합 방식으로 유연한 설정 시스템 구축
- **클라이언트 래퍼**: `OpenAIClient` 클래스로 API 연결, 상태 관리, 에러 처리
- **서버 통합**: Fastify 서버에 OpenAI 클라이언트 통합, 헬스체크 연동
- **문서화**: 기술 의사결정 2개, 개념 설명 1개 문서 작성
- **테스트**: 통합 테스트 + 단위 테스트 39개 (100% 통과, 0.68초 실행)
- **검증**: 실제 OpenAI API 연결 테스트 성공 (58개 모델 접근 가능)

#### 3-2단계 구현 완료 사항 ✅
- **EmbeddingService 핵심 기능**: 
  - 단일 텍스트 임베딩: `createEmbedding(text)` → 1536차원 벡터 
  - 배치 처리: `createBatchEmbeddings()` 여러 텍스트 일괄 처리
  - 긴 텍스트 처리: `createEmbeddingForLongText()` 자동 청킹 → 여러 벡터
- **토큰 처리 시스템**: 
  - tiktoken 기반 정확한 토큰 계산 (OpenAI와 100% 동일)
  - 8191 토큰 제한 검증 및 자동 텍스트 청킹
  - 200토큰 오버랩으로 문맥 연속성 보장
- **고급 기능**: 
  - FIFO 캐싱으로 중복 요청 방지 (메모리 효율적)
  - 지수 백오프 재시도 로직 (rate limit 대응)
  - 실시간 사용량 추적 ($0.02/1M tokens)
- **성능 최적화**: 
  - 테스트 실행시간 83% 개선 (9초 → 1.5초)
  - tiktoken 성능 검증 (1-8ms, 사용자 인지 불가능)
- **포괄적 테스트**: 20+ 테스트 케이스, 모든 엣지 케이스 커버
- **기술 문서화**: tiktoken 선택 의사결정, 구현 상세 설명 문서 완료

#### 3단계 구현 수준 평가 🔍
- **복잡성**: 기본 OpenAI 임베딩 구현 대비 **90배 복잡** (911줄 vs 10줄)
- **고도화 정도**: 프로덕션 레디 수준의 완성도
  - tiktoken, 캐싱, 재시도 로직, 배치 처리 등 고급 기능 포함
  - 일반적인 RAG 초기 구현보다 상당히 높은 완성도
- **초기 단계 대비 평가**: 과도한 엔지니어링이었으나, 이미 완성된 상황에서는 유지하는 것이 실용적
- **향후 개발 방향성 조정**: 4단계부터는 최소 기능 우선 원칙 적용

## 향후 개발 방향성 조정 📋

### 개발 원칙 변경 (4단계부터 적용)
3단계까지는 높은 완성도로 구현되었으나, 초기 RAG 시스템 구축 목적에는 과도한 엔지니어링이었음을 인정하고, 향후 개발에서는 다음 원칙을 엄격히 적용:

#### **새로운 개발 원칙**
1. **최소 기능으로 시작 (MVP First)**
   - RAG가 동작하는 최소 기능만 우선 구현
   - "Just Enough" 엔지니어링 추구
   
2. **필요할 때만 확장 (Progressive Enhancement)**
   - 실제 문제가 발생했을 때 최적화 추가
   - 추측성 최적화 금지

3. **과도한 엔지니어링 자제**
   - 복잡한 에러 처리, 캐싱, 배치 처리 등은 필요 시에만 추가
   - 기본 구현으로도 충분한지 먼저 확인

#### **적용 방법**
- 각 단계 계획 시 "기본 구현" vs "고급 기능" 명확히 구분
- 고급 기능은 "향후 개선사항"으로 분류하여 별도 관리
- 단계별 완료 기준을 "동작하는 최소 기능" 수준으로 설정

---

### 4단계: 벡터 DB (Pinecone) 연동 🔍
**예상 소요시간**: 1.5-2시간 (최소 기능 우선)  
**목표**: RAG가 동작하는 기본 벡터 저장/검색 기능 구현

#### 최소 기능 구현 (필수)
- [ ] **기본 Pinecone 연결**
  - PineconeClient 클래스 생성 (연결, 기본 에러 처리)
  - 환경변수 설정 및 인덱스 연결
  
- [ ] **핵심 벡터 작업**
  - `upsert()`: 벡터 저장 (ID + 벡터 + 간단한 메타데이터)
  - `query()`: 벡터 검색 (쿼리 벡터 → 유사 벡터 반환)
  - 간단한 임계값 필터링 (score >= 0.7)

- [ ] **기본 타입 정의**
  ```typescript
  interface VectorData {
    id: string;
    vector: number[];
    metadata: { title: string; content: string; source: string; }
  }
  
  interface SearchResult {
    id: string;
    score: number;
    metadata: any;
  }
  ```

- [ ] **헬스체크 통합**
  - 기존 헬스체크에 Pinecone 연결 상태 추가
  - 간단한 인덱스 상태 확인

- [ ] **기본 단위 테스트**
  - upsert, query, healthCheck 메서드 테스트
  - 모킹 기반 테스트 (실제 API 호출 최소화)

#### 향후 개선사항 (나중에 추가)
- 배치 업로드 최적화
- 복잡한 메타데이터 스키마
- 고급 필터링 및 정렬
- 재시도 로직 및 에러 처리 강화
- 성능 모니터링

#### 완료 기준 (최소 동작 수준)
- [x] EmbeddingService 결과를 Pinecone에 저장 가능
- [x] 쿼리 벡터로 유사 문서 검색 가능 (기본 임계값 적용)
- [x] 헬스체크에서 Pinecone 연결 상태 확인 가능
- [x] 단위 테스트 통과 (기본 시나리오만)
- [x] RAG 워크플로우 완성: 문서 → 임베딩 → 벡터 저장 → 검색 동작

---

### 5단계: 임베딩 생성 & 저장 파이프라인 🔄
**예상 소요시간**: 2-3시간  
**목표**: 노션 문서를 벡터로 변환하여 저장하는 전체 파이프라인

#### 작업 내용
- [ ] **문서 처리 파이프라인**
  - 노션 문서 → 청크 분할 → 임베딩 생성 → Pinecone 저장
  - 중복 처리 방지 (문서 해시 기반)
  - 진행상황 로깅

- [ ] **증분 업데이트**
  - 변경된 문서만 다시 처리
  - 삭제된 문서 벡터 제거
  - 배치 작업 스케줄링

- [ ] **관리 API 추가**
  - `/api/documents/refresh` - 전체 문서 재처리
  - `/api/documents/stats` - 처리 통계 확인

#### 완료 기준
- 노션 → Pinecone 전체 파이프라인 동작
- 문서 변경사항 자동 감지 및 업데이트
- 관리 API를 통한 수동 제어 가능

---

### 6단계: RAG 로직 + LLM 호출 구현 💬🤖
**예상 소요시간**: 3-4시간  
**목표**: 질문 → 벡터 검색 → LLM 응답 전체 플로우

#### 작업 내용
- [ ] **LLM 호출 서비스 구현**
  - `LLMService` 클래스 생성
  - 기본 채팅 완료 API 호출
  - 프롬프트 템플릿 시스템
  - 응답 스트리밍 준비 구조

- [ ] **RAG 파이프라인 구현**
  - 사용자 질문 → 임베딩 변환
  - 벡터 검색으로 관련 문서 추출
  - 컨텍스트 + 질문 → LLM 프롬프트 생성
  - LLM 응답 생성 및 후처리

- [ ] **응답 품질 개선**
  - 프롬프트 엔지니어링
  - 컨텍스트 길이 최적화
  - 신뢰도 점수 계산

- [ ] **오류 상황 처리**
  - 관련 문서 없음 → 적절한 안내 메시지
  - API 호출 실패 → 재시도 로직
  - 응답 타임아웃 → 사용자 알림

#### 완료 기준
- 질문에 대한 적절한 답변 생성 가능
- 출처 정보 포함된 응답 제공
- 다양한 에러 상황 적절히 처리

---

### 7단계: REST 채팅 API 생성 🌐
**예상 소요시간**: 1-2시간  
**목표**: 기본적인 채팅 API 엔드포인트 구현

#### 작업 내용
- [ ] **채팅 API 구현**
  - `POST /api/chat` 엔드포인트
  - 요청/응답 검증 (Zod 스키마)
  - 에러 처리 및 상태 코드

- [ ] **API 문서화**
  - 요청/응답 스키마 정의
  - 예시 요청/응답 작성
  - 에러 코드 정의

#### 완료 기준
- REST API로 채팅 기능 완전 동작
- API 문서 작성 완료
- Postman/curl로 테스트 가능

---

### 8단계: FE 프로젝트 + 기본 UI 🎨
**예상 소요시간**: 4-6시간  
**목표**: 기본적인 웹 UI로 채팅 기능 테스트

#### 작업 내용
- [ ] **FE 프로젝트 생성**
  - Next.js 또는 React + Vite 선택
  - TypeScript 설정
  - 기본 UI 라이브러리 (Tailwind CSS)

- [ ] **채팅 UI 구현**
  - 메시지 목록 표시
  - 질문 입력 폼
  - 로딩 상태 표시
  - 출처 정보 표시

- [ ] **REST API 연동**
  - HTTP 클라이언트 설정
  - 에러 처리
  - 응답 상태 관리

#### 완료 기준
- 웹 브라우저에서 채팅 기능 사용 가능
- 출처 정보 클릭으로 원본 문서 접근 가능
- 기본적인 UX/UI 완성

---

### 9단계: 소켓 연동으로 업그레이드 ⚡
**예상 소요시간**: 3-4시간  
**목표**: 실시간 스트리밍 응답 구현

#### 작업 내용
- [ ] **Socket.io 서버 설정**
  - Fastify Socket.io 플러그인 추가
  - 네임스페이스 및 룸 관리
  - 연결 상태 관리

- [ ] **스트리밍 응답 구현**
  - OpenAI 스트리밍 API 활용
  - 실시간 토큰 전송
  - 진행상황 표시

- [ ] **FE 소켓 클라이언트**
  - Socket.io 클라이언트 연동
  - 실시간 메시지 수신
  - 연결 상태 표시

#### 완료 기준
- 실시간으로 응답이 스트리밍됨
- 연결 끊김/재연결 처리
- 여러 사용자 동시 접속 지원

---

## 마일스톤 및 검증 포인트

### 마일스톤 1: 데이터 연동 완료 (1-4단계)
- [x] 노션에서 문서 읽기 가능 ✅
- [x] OpenAI API 연결 및 기본 설정 완료 ✅ (3-1단계)
- [x] OpenAI 임베딩 생성 기능 구현 ✅ (3-2단계)
- [ ] Pinecone에 벡터 저장/검색 가능
- [x] 헬스체크에서 모든 서비스 상태 확인 ✅

### 마일스톤 2: RAG 시스템 완성 (5-6단계)
- [ ] 노션 → Pinecone 파이프라인 동작
- [ ] 질문 → 답변 전체 플로우 완성
- [ ] 적절한 품질의 응답 생성

### 마일스톤 3: 사용자 인터페이스 완성 (7-9단계)
- [ ] REST API 완전 동작
- [ ] 웹 UI에서 채팅 사용 가능
- [ ] 실시간 스트리밍 응답 구현

## 위험 요소 및 대응 방안

### 기술적 위험
- **Pinecone API 제한**: 배치 크기 조정 및 재시도 로직
- **OpenAI 토큰 제한**: 컨텍스트 길이 최적화
- **노션 API Rate Limit**: 요청 간격 조정

### 개발 위험
- **타입 정의 불일치**: 각 단계마다 타입 검증 강화
- **성능 이슈**: 각 단계별 성능 측정 및 최적화
- **데이터 일관성**: 트랜잭션 및 롤백 메커니즘

## 성공 기준

### 기능적 요구사항
- [ ] 노션 문서 기반 질의응답 가능
- [ ] 실시간 스트리밍 응답 제공
- [ ] 출처 정보 포함된 답변
- [ ] 관련 문서 없을 때 적절한 안내

### 비기능적 요구사항
- [ ] 응답 시간 5초 이내
- [ ] 동시 사용자 10명 이상 지원
- [ ] 99% 이상 가용성
- [ ] 타입 안전성 보장

---

**현재 진행**: [4단계: 벡터 DB (Pinecone) 연동] 준비  
**최종 수정일**: 2025-08-07 16:15  
**책임자**: Development Team

## 개발 진행 현황 (2025-08-07 16:15 업데이트)

### 완료된 단계
1. **1단계**: 기초 구조 구축 ✅ 
2. **2단계**: 노션 데이터베이스 연동 ✅ (포괄적 테스트 포함)
3. **3-1단계**: OpenAI 기본 설정 및 연결 ✅ (의사결정 문서 + 단위 테스트)
4. **3-2단계**: 임베딩 서비스 구현 ✅ (tiktoken 통합, 성능 최적화 완료)

### 다음 작업
- **4단계**: 벡터 DB (Pinecone) 연동 🔄

### 주요 성과
- **총 테스트**: 105개+ (100% 통과, 실행시간 < 2초)
- **문서화**: 기술 의사결정 3개, 개념 설명 1개, 코드 설명 1개
- **실제 API 검증**: Notion ✅, OpenAI ✅ (임베딩 생성 포함)
- **타입 안전성**: TypeScript strict 모드 + Jest 타입 완전 지원
- **성능 최적화**: 테스트 실행 시간 83% 개선, tiktoken 성능 검증 완료