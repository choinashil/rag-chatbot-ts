# 단순 HTML 텍스트 추출 방식 - 최종 채택 방안

> **작성일**: 2025-08-09 22:00 KST  
> **대상**: Sixshop Pro 가이드 문서 HTML 단순 텍스트 추출  
> **목적**: 벡터화를 위한 최적화된 텍스트 추출 방식 확정  
> **상태**: ✅ **최종 채택 및 구현 완료**

## 개요

복잡한 의미론적 청킹 방식을 포기하고, **단순한 전체 페이지 텍스트 추출** 방식을 최종 채택했습니다. 이는 노션 API 방식과 복잡한 HTML 파싱 방식을 모두 테스트한 결과, 실용성과 효율성 측면에서 가장 우수한 방식으로 판단되었습니다.

## 방식 비교 테스트 결과

### 1. **노션 API 방식** (채택되지 않음)
**장점:**
- 사용자가 노션에 작성했을 때의 표현 의도를 디테일하게 파악 가능
- 어떤 종류의 블록을 사용했는지 정확히 알 수 있음
- 구조화된 데이터로 세밀한 처리 가능

**단점:**
- `column_list` 등 하위 블록을 가질 수 있는 블록에서 재귀적 추가 호출 필요
- 다양한 블록 종류에 따라 각각 다른 처리 로직 필요 (복잡도 증가)
- 내부 URL로 인한 사용자 접근성 제한
- API 호출 비용 및 속도 이슈

### 2. **복잡한 HTML 파싱 방식** (채택되지 않음)  
**장점:**
- 의미론적 구조 보존
- 계층적 청킹을 통한 컨텍스트 관리

**단점:**
- 개발 복잡도 과도함 (실제 이익 대비)
- 메모리 사용량 증가
- oopy 특성상 하위 페이지 내용이 혼재되어 부정확성 발생
- 과도한 엔지니어링으로 인한 유지보수 부담

### 3. **단순 HTML 텍스트 추출 방식** ✅ **최종 채택**
**장점:**
- 한 번에 전체 HTML을 불러올 수 있어 요청 성능 최적화
- 단순하고 안정적인 구조로 유지보수 용이
- 벡터 검색에 최적화된 순수 텍스트 제공
- 메모리 효율적이고 처리 속도 빠름

**단점:**
- 노션 작성자의 의도 파악 어려움 (블록 종류별 처리 불가)
- SSR 된 내용만 참조 가능 (CSR UI는 누락)
- oopy에서 하위 페이지 내용이 일부 포함되어 약간의 부정확성 존재

**채택 이유:**
- **실용성 우선**: 벡터 검색에서는 의미적 내용이 구조보다 중요
- **성능 최적화**: 단순한 구조로 빠른 처리 및 낮은 자원 사용
- **업계 표준 부합**: OpenAI, Pinecone 등에서 권장하는 순수 텍스트 방식

## 최종 아키텍처

### **데이터 구조**
```typescript
interface VectorDocument {
  content: string           // 순수 텍스트 (Search 이후 부분)
  metadata: {
    url: string,
    title: string,
    breadcrumb: string[]    // 계층 정보
  }
}
```

### **처리 플로우**
```
1. axios → HTML 수집
2. cheerio → DOM 파싱 및 불필요 요소 제거
3. .text() → 순수 텍스트 추출  
4. 'Search' 기준 분할 → breadcrumb 분리 (oopy 페이지의 '검색' 키워드 기준으로 분리)
5. 벡터 DB 저장
```

### **핵심 기술 결정**
- **텍스트 저장**: 순수 텍스트만 저장 (마크다운 링크 제거)
- **breadcrumb**: 메타데이터로 별도 관리 (검색 품질 향상)
- **분할 방식**: `split('Search')` 사용 (유지보수성)
- **라이브러리**: axios + cheerio 조합 (업계 표준)

## 구현 완료 현황

### ✅ 구현 완료 항목
- [x] 단순 HTML 텍스트 추출 스크립트 (`simple-html-parser.ts`)
- [x] axios + cheerio 기반 안정적 HTML 수집
- [x] Search 기준 breadcrumb 분리
- [x] 순수 텍스트 벡터 저장 방식
- [x] 두 테스트 페이지 검증 완료

### **테스트 결과**
```
웹사이트 디자인 페이지: 793자 순수 텍스트
웹사이트 디자인 입문하기: 2,092자 순수 텍스트
breadcrumb: 100% 정확한 계층 구조 추출
성능: 메모리 효율적, 빠른 처리 속도
```

## 다음 단계 계획

### **3단계: 다중 페이지 수집 시스템** ✅ **완료**
#### 목표
단일 페이지 추출에서 발전하여 사이트 전체를 체계적으로 수집하는 시스템 구축

#### 핵심 기능 ✅ **구현 완료**
- [x] 아키텍처 설계 완료
- [x] **재귀적 사이트 크롤링**: 시작 URL에서 출발하여 내부 링크를 따라가며 페이지 수집
- [x] **페이지 간 관계 매핑**: 부모-자식 관계 추적 및 사이트 구조 파악
- [x] **중복 제거 및 우선순위 관리**: URL 정규화, 중복 페이지 제거, 처리 우선순위 설정

#### 구현 결과 ✅ **개선 완료**

**🐛 발견된 문제 (해결됨)**:
- **중복 크롤링**: 시작 페이지가 두 번 크롤링됨 (visited URL 처리 오류)
- **URL 정규화**: 같은 페이지가 다른 URL로 인식되어 중복 처리

**✅ 해결된 개선사항**:
- **콘텐츠 기반 중복 검사**: URL 기반에서 콘텐츠 기반으로 확장
- **효율적인 중복 감지**: 제목 + 콘텐츠 길이 조합으로 중복 검사
- **실제 테스트 검증**: 중복 페이지 1개 감지 및 건너뛰기 확인

#### 중복 검사 방식 분석 및 선택

**검토된 중복 검사 방법들**:

| 방식 | 속도 | 메모리 | 정확도 | 오탐률 | 미탐률 | 비고 |
|------|------|--------|--------|--------|--------|------|
| URL 기반 | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐ | 낮음 | 높음 | 기존 방식 |
| **제목+길이** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | 보통 | 보통 | **채택됨** |
| 전체 MD5 | ⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 매우낮음 | 매우낮음 | 성능 부담 |
| 부분 비교 | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ | 낮음 | 낮음 | 향후 고려 |

**최종 선택: 제목 + 콘텐츠 길이 기반**
- **구현 방식**: `${title.trim()}_${contentLength}` 해시 생성
- **선택 근거**: 성능과 정확도의 최적 균형점
- **테스트 결과**: 실제 중복 페이지 1개 감지 및 건너뛰기 성공

**향후 개선 옵션 (필요 시 적용)**:
- **2단계 중복 검사**: 빠른 검사(제목+길이) + 정밀 검사(부분 콘텐츠)
- **적응적 방식**: 콘텐츠 길이에 따른 동적 검사 방식 조정
- **부분 콘텐츠 비교**: 처음 500-1000자 추출하여 비교

1. **HtmlCrawlerService**: 크롤링 엔진 구현 ✅
   - ✅ 재귀적 페이지 탐색 (최대 깊이 2단계까지 정상 작동)
   - ✅ 동시성 제어 (concurrency 2개 동시 처리)
   - ✅ 크롤링 지연 (2초 지연으로 서버 부하 방지)

2. **PageRelationMapper**: 관계 매핑 시스템 ✅
   - ✅ 링크 추출 및 분류 (158개 내부 링크, 3개 외부 링크 발견)
   - ✅ 부모-자식 관계 추적 (parentUrl 필드로 관계 매핑)
   - ✅ 사이트 계층 구조 생성 (깊이별 문서 분류 및 시각화)

3. **DuplicationManager**: 중복 관리 시스템 ✅ **완료**
   - ✅ 콘텐츠 기반 중복 검사 (제목 + 콘텐츠 길이 기반)
   - ✅ URL 정규화 및 중복 검사 개선
   - ✅ 도메인 제한 적용 (help.pro.sixshop.com만 허용)
   - ✅ 처리 상태 관리 (visited URLs + content hashes 통합 관리)

#### 기술적 고려사항
- **성능**: 적절한 동시성과 지연으로 서버 부하 최소화
- **안정성**: robots.txt 준수, 에러 처리, 재시도 로직
- **확장성**: 대용량 사이트 처리 가능한 구조

### **4단계: HTML 파서 전략 패턴 리팩토링** ✅ **완료**
- ✅ 전략 패턴 도입 및 사이트별 파싱 로직 분리 (Phase 1-2 완료)
- ✅ oopy 자동 감지 시스템 구현 (URL + HTML 내용 기반 감지)
- ✅ Generic 파서로 일반 HTML 사이트 지원 (Phase 3 완료)
- ✅ HtmlService 리팩토링 및 하위 호환성 유지 (Phase 4 완료)
- ✅ 확장 가능한 아키텍처 구축 (향후 WordPress, Notion 등 파서 추가 용이)
- ✅ 포괄적인 테스트 코드 작성 및 검증 (Phase 5 완료)
  - 파서별 독립적인 단위 테스트 (`oopy-parser.test.ts`, `generic-parser.test.ts`)
  - 기존 테스트 모두 통과 (254/254 단위 + 7/7 통합)
  - 일반 HTML 사이트 파싱 기능 동작 확인

#### 구현 결과 
```
src/services/html/
├── parsers/
│   ├── oopy-parser.ts          # oopy 사이트 전용 파서
│   ├── generic-parser.ts       # 일반 HTML 파서 (fallback)
│   └── index.ts               # 파서들 export
├── html-parser.manager.ts      # 전략 선택 및 관리
└── html.service.ts            # 리팩토링된 메인 서비스
```

**핵심 개선사항:**
- **타입 안전성**: `ParserName = 'oopy' | 'generic'` 타입 제한
- **자동 감지**: URL 기반 + HTML 내용 기반 oopy 사이트 감지
- **확장성**: 새로운 파서 추가 시 기존 코드 수정 없이 가능
- **하위 호환성**: 기존 HtmlService API 완전 호환


## 교훈 및 인사이트

### **개발 접근법**
- **MVP 우선**: 복잡한 설계보다 동작하는 단순한 솔루션이 우선
- **실용성 중심**: 이론적 완벽함보다 실제 사용성과 유지보수성 고려
- **점진적 개선**: 기본 동작 확보 후 필요 시에만 복잡도 추가

### **기술 선택 기준**
- **업계 표준 준수**: 검증된 방식 우선 채택
- **성능과 단순성**: 과도한 엔지니어링 지양
- **확장 가능성**: 향후 개선이 용이한 구조

---

### **코드 품질 개선 완료** ✅ **2025-08-10 18:23 KST**

#### 개선 항목
- [x] **Breadcrumb 기반 상대 깊이 계산**: 절대 깊이 대신 breadcrumb 길이 기반 상대 깊이로 개선
- [x] **부모 페이지 크롤링 제어**: `includeParentPages` 옵션 추가 (기본값: false)
- [x] **코드 주석 개선**: contentHashes, startBreadcrumbDepth 필드에 상세 주석 추가
- [x] **미사용 코드 제거**: isPromiseResolved, generateContentHash, 사용되지 않는 sessionId 필드 제거
- [x] **Deprecated 메서드 대체**: substr → slice 변경으로 TypeScript 경고 해결

#### 개선 효과
- **정확한 깊이 제어**: breadcrumb 기반으로 실제 사이트 구조를 반영한 깊이 계산
- **부모 페이지 제어**: 시작점보다 상위 페이지 크롤링 여부를 옵션으로 제어 가능
- **코드 품질 향상**: TypeScript 컴파일 경고 0개, 불필요한 코드 제거로 유지보수성 개선

### **추가 개선사항 완료** ✅ **2025-08-10 18:30 KST**

#### 로직 개선 및 용어 정정
- [x] **용어 변경**: "절대깊이" → "탐색깊이"로 명확성 향상
- [x] **부모 페이지 제한 개선**: `includeParentPages: false`일 때 형제 페이지는 허용하도록 수정
- [x] **동일 레벨 콘텐츠 허용**: 시작 페이지와 같은 레벨의 다른 섹션 콘텐츠 포함
- [x] **콘솔 출력 간격 개선**: 페이지 간 구분을 위한 빈 줄 추가로 가독성 향상
- [x] **로그 순서 개선**: 하위 링크 추가 로그가 완료 로그 이전에 출력되도록 수정
- [x] **상세한 로깅**: 부모/형제 페이지 구분, 하위 링크 추가 개수 표시 등 디버깅 정보 강화

#### 핵심 로직 변경사항
```typescript
// 이전: 부모 + 형제 페이지 스킵
if (relativeDepth <= 0 && depth > 0 && !session.options.includeParentPages)

// 현재: 부모 페이지만 스킵, 형제 페이지는 허용
if (relativeDepth < 0 && depth > 0 && !session.options.includeParentPages)
```

#### 최종 동작 방식
**includeParentPages: false (기본값):**
- **시작 페이지**: 상대깊이 0, 탐색깊이 0 → ✅ 처리 (예외 처리)
- **자식 페이지**: 상대깊이 > 0 → ✅ 처리 및 하위 링크 탐색
- **형제 페이지**: 상대깊이 0, 탐색깊이 > 0 → ✅ 처리 및 하위 링크 탐색
- **부모 페이지**: 상대깊이 < 0 → ❌ 스킵, 하위 링크 차단

#### 개선 효과
- **정확한 크롤링 범위**: 시작 페이지 기준 하위 페이지만 체계적으로 수집
- **불필요한 크롤링 방지**: 부모/형제 페이지의 하위 링크까지 차단하여 효율성 증대
- **명확한 용어 사용**: 탐색깊이와 상대깊이 개념 구분으로 코드 이해도 향상
- **향상된 사용성**: 직관적인 로그 출력으로 크롤링 과정 추적 용이

---

### **4단계: HTML 파서 전략 패턴 리팩토링** ✅ **구현 완료** 🎉

#### 배경 및 필요성 (완료)
하드코딩된 oopy 전용 로직을 전략 패턴으로 리팩토링하여 다양한 사이트 유형을 지원하는 확장 가능한 아키텍처를 구축했습니다.

#### 주요 개선사항 ✅ **완료**
- ✅ **전략 패턴 도입**: 사이트별 파싱 로직을 독립적인 전략 클래스로 분리 완료
- ✅ **oopy 자동 감지**: URL 및 HTML 내용 기반으로 oopy 사이트 정확한 감지 시스템 구현
- ✅ **Generic 파서**: 일반 HTML 사이트 기본 지원 (title, body 추출, breadcrumb 빈 배열)
- ✅ **확장 가능한 구조**: 향후 WordPress, Notion 등 추가 지원 용이
- ✅ **포괄적인 테스트**: 58개 테스트 모두 통과

#### 구현 결과 ✅ **완료**
```
src/
├── types/html-parser.ts                    # 파서 전략 인터페이스
└── services/html/
    ├── parsers/
    │   ├── oopy-parser.ts              # oopy 전용 파서
    │   ├── generic-parser.ts           # 일반 HTML 파서
    │   └── index.ts                   # 파서들 export
    ├── html-parser.manager.ts          # 전략 선택 및 관리
    └── html.service.ts                 # 리팩토링된 메인 서비스
```

#### 기술적 개선사항 ✅
- **타입 안전성**: ParserName = 'oopy' | 'generic' 타입 제한
- **상수화**: 'Search' 키워드 등 매직 넘버 상수로 밴출
- **하드코딩 제거**: 기존 HtmlService에서 oopy 전용 로직 완전 분리
- **확장 가능**: 새로운 파서 추가 시 기존 코드 수정 없이 가능

**상세 구현 계획**: [`250810-1830-html-parser-strategy-refactoring.md`](./250810-1830-html-parser-strategy-refactoring.md)

---

**현재 상태**: ✅ HTML 텍스트 추출 방식 확정 및 구현 완료  
**완료된 단계**: Stage 1-4 (HTML 텍스트 추출, 다중 페이지 수집, 파서 전략 패턴)  
**다음 작업**: HTML 벡터화 관련 작업은 별도 문서 참조  
**최종 수정일**: 2025-08-10 21:35 KST  
**책임자**: Development Team