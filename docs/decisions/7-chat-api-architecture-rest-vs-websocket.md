# 채팅 API 아키텍처: REST vs WebSocket vs SSE

> RAG 채팅 시스템에서 실시간 상황 전달을 위한 최적 기술 스택 선택

## 1. 배경

RAG 채팅 시스템에서 LLM 추론 과정이 길어질 경우(5-15초), 사용자에게 진행 상황을 알리고 응답을 실시간으로 스트리밍하는 것이 사용자 경험에 핵심적입니다. 

현재 계획에서는 7단계에서 REST API로 시작하고 9단계에서 스트리밍을 추가하도록 되어 있으나, 챗봇의 실시간 특성을 고려할 때 초기부터 적절한 실시간 통신 방식을 선택하는 것이 중요합니다.

## 2. 검토 대상

### 옵션 1: REST API 전용
- HTTP POST 요청/응답 방식
- 동기적 처리, 응답 완료까지 대기
- 가장 단순한 구현

### 옵션 2: Server-Sent Events (SSE)
- HTTP 기반 서버 → 클라이언트 스트리밍
- EventSource API 활용
- 단방향 실시간 통신

### 옵션 3: WebSocket
- 양방향 실시간 통신
- Socket.io 또는 네이티브 WebSocket
- 상태 관리 및 연결 유지 필요

### 옵션 4: 점진적 접근 (REST → SSE)
- 7단계: REST API로 기본 기능 구현
- 9단계: SSE 추가로 스트리밍 개선
- 향후: 필요시 WebSocket 업그레이드

## 3. 의사결정 과정

### 각 기술별 특성 비교

#### REST API
**장점**
- **구현 단순성**: HTTP 기반으로 테스트, 디버깅, 캐싱 용이
- **무상태성**: 서버 확장성 좋음, 로드밸런싱 간단
- **표준화**: curl, Postman 등 도구 활용 가능
- **인프라 친화적**: 방화벽, 프록시, CDN 등과 호환성 좋음
- **학습 곡선**: 기존 웹 개발 지식 활용 가능

**단점**
- **실시간성 부족**: 긴 응답시간(5-15초) 동안 사용자 대기 필수
- **사용자 경험**: 응답 중 진행 상황 알 수 없어 답답함
- **폴링 필요**: 진행 상황 확인을 위한 추가 요청 오버헤드

#### Server-Sent Events (SSE)
**장점**
- **실시간 스트리밍**: 서버 → 클라이언트 실시간 데이터 전송
- **HTTP 기반**: REST API 인프라 그대로 활용
- **자동 재연결**: 브라우저 내장 기능으로 연결 복구
- **구현 단순성**: WebSocket보다 간단, EventSource API 활용
- **점진적 향상**: 기존 REST API에 스트리밍 추가 가능
- **캐싱/CDN**: HTTP 기반이라 기존 인프라 활용

**단점**
- **단방향**: 클라이언트 → 서버는 별도 HTTP 요청 필요
- **브라우저 연결 제한**: 도메인당 6개 연결 제한 (HTTP/1.1) - 개별 사용자별 제한
- **복잡한 상태 관리**: 스트리밍 중 에러 처리, 상태 동기화

> **⚠️ SSE 연결 제한 상세 설명**  
> 도메인당 6개 연결 제한은 **개별 브라우저별 제한**입니다:
> - **개별 사용자**: 한 브라우저에서 같은 도메인에 최대 6개 SSE 연결
> - **전체 사용자**: 서버는 수천~수만 명의 동시 SSE 연결 처리 가능
> - **실제 영향**: 한 사용자가 6개 이상의 탭에서 SSE 사용시에만 문제
> - **RAG 챗봇**: 일반적으로 탭 1개만 사용하므로 문제없음

#### WebSocket
**장점**
- **양방향 실시간 통신**: 즉시 양방향 통신, 낮은 지연시간
- **연결 유지**: 한 번 연결로 다중 메시지 처리, 오버헤드 적음
- **유연성**: 텍스트, 바이너리 데이터 모두 지원
- **사용자 경험**: 가장 자연스러운 실시간 채팅 경험
- **진행 상황**: 복잡한 상태 정보도 실시간 전달 가능

**단점**
- **구현 복잡성**: 연결 관리, 재연결, 하트비트, 에러 처리 복잡
- **상태 관리**: 연결별 세션 상태 서버에서 관리 필요
- **확장성**: 서버 메모리 사용량 높음, 연결 수 제한
- **디버깅**: HTTP 도구 사용 불가, 전용 디버깅 도구 필요
- **인프라 복잡도**: 로드밸런서 sticky session, 프록시 설정 등

## 4. RAG 챗봇 특성 분석

### 챗봇 사용자 경험 요구사항
1. **응답 시간**: LLM 추론으로 5-15초 소요
2. **진행 상황**: "문서 검색 중", "답변 생성 중" 등 상태 표시 필요  
3. **스트리밍**: 응답을 실시간으로 타이핑하며 표시
4. **사용 패턴**: 일반적으로 단발성 질문, 연속 대화는 제한적

### 기술적 고려사항
- **OpenAI 스트리밍 API**: 이미 스트리밍 지원으로 SSE와 자연스럽게 연동
- **서버 부하**: 동시 연결 수가 많지 않을 것으로 예상 (초기 단계)
- **개발 리소스**: 빠른 MVP 구현 및 검증 우선

## 5. 최종 결정: **Server-Sent Events (SSE) 우선 접근**

### 선택 근거
1. **사용자 경험 우선**: 챗봇에서 실시간 응답은 필수 기능
2. **OpenAI 연동 최적화**: 스트리밍 API와 SSE의 자연스러운 매칭
3. **구현 효율성**: WebSocket 대비 단순하면서도 필요 기능 충족
4. **인프라 호환성**: REST API 인프라 그대로 활용 가능
5. **점진적 확장성**: 필요시 WebSocket으로 업그레이드 용이

### 기각된 옵션들의 이유
- **REST 전용**: 챗봇의 핵심 가치인 실시간 응답 경험 제공 불가
- **WebSocket 우선**: 단순한 단방향 스트리밍에 과도한 복잡성
- **점진적 접근 (REST→SSE)**: 초기부터 필수인 기능을 나중으로 미룸

## 6. 구현 전략

### 7단계: SSE 기반 스트리밍 채팅 API
```typescript
// 메인 스트리밍 엔드포인트
GET /api/chat/stream?message=질문
Content-Type: text/event-stream

// 이벤트 스트림 형태
data: {"type": "status", "content": "문서 검색 중..."}
data: {"type": "status", "content": "답변 생성 중..."}  
data: {"type": "token", "content": "안녕"}
data: {"type": "token", "content": "하세요"}
data: {"type": "sources", "content": [sources]}
data: {"type": "done"}
```

### 7단계: 백업용 REST API (선택사항)
```typescript
// 스트리밍 미지원 환경을 위한 폴백
POST /api/chat
Request: { message: string }
Response: { response: string, sources: Source[] }
```

### OpenAI 스트리밍 연동
```typescript
// RAGService에서 OpenAI 스트리밍 직접 연동
const stream = openai.chat.completions.create({
  model: "gpt-3.5-turbo",
  messages: messages,
  stream: true
});

for await (const chunk of stream) {
  const token = chunk.choices[0]?.delta?.content;
  if (token) {
    // SSE로 토큰 전송
    res.write(`data: ${JSON.stringify({type: "token", content: token})}\n\n`);
  }
}
```

### 향후: WebSocket 업그레이드 고려 조건
다음 중 하나 이상 필요시 WebSocket 검토:
- **대화 기록 실시간 동기화**: 여러 탭/기기 간 대화 상태 공유
- **다중 사용자 채팅**: 그룹 채팅, 공동 작업 기능
- **양방향 상호작용**: 사용자 입력 실시간 처리, 타이핑 상태 표시
- **복잡한 상태 관리**: 연결별 개인화, 세션 상태 유지

## 7. 향후 고려사항

### 성능 모니터링 지표
- **첫 토큰 지연시간**: 질문 후 첫 응답 토큰까지의 시간 (목표: 3초 이내)
- **스트리밍 안정성**: 연결 끊김, 재연결 성공률
- **사용자 만족도**: 실시간 응답에 대한 사용자 피드백
- **서버 리소스**: SSE 연결별 메모리 사용량, CPU 사용률

### 기술 업그레이드 시점
- **첫 토큰 지연이 5초 초과**: OpenAI API 최적화 또는 캐싱 고려
- **동시 사용자 50명 초과**: 연결 관리 및 스케일링 방안 검토  
- **양방향 기능 요구**: WebSocket 업그레이드 검토
- **브라우저 호환성 이슈**: 폴백 REST API 강화

### 호환성 유지 전략
- **점진적 도입**: SSE 미지원 브라우저를 위한 REST 폴백 제공
- **기능 감지**: 클라이언트에서 EventSource 지원 여부 확인 후 적절한 API 선택
- **API 버저닝**: v1 (SSE), v2 (WebSocket) 등으로 구분하여 하위 호환성 보장

### 개발 계획 수정 제안
- **7단계**: REST API → SSE 스트리밍 API로 변경
- **8단계**: 웹 UI에서 EventSource API 연동
- **9단계**: 고급 기능 (대화 기록, 사용자 인증 등) 추가

---
**작성일**: 2025-08-08  
**작성자**: Development Team  
**다음 리뷰**: 7단계 SSE 구현 완료 후 (스트리밍 성능 평가 시점)  
**업데이트**: REST vs WebSocket vs SSE 3가지 비교로 확장, SSE 우선 접근으로 결정 변경