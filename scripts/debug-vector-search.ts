#!/usr/bin/env tsx
/**
 * ë²¡í„° ê²€ìƒ‰ ë””ë²„ê¹… ìŠ¤í¬ë¦½íŠ¸
 * ìž„ê³„ê°’ ì—†ì´ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ì—¬ ì‹¤ì œ ìœ ì‚¬ë„ ì ìˆ˜ë¥¼ í™•ì¸
 */

import dotenv from 'dotenv'
import { EmbeddingService } from '../src/services/openai/embedding.service'
import { PineconeService } from '../src/services/pinecone/pinecone.service'
import { OpenAIClient } from '../src/services/openai/openai.client'
import { PineconeClient } from '../src/services/pinecone/pinecone.client'
import { createOpenAIConfig } from '../src/config/openai'
import { createPineconeConfig } from '../src/config/pinecone'

// í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
dotenv.config({ path: 'env/.env.integration' })

async function debugVectorSearch() {
  console.log('ðŸ” ë²¡í„° ê²€ìƒ‰ ë””ë²„ê¹… ì‹œìž‘...')
  
  try {
    // ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    console.log('\n1. ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...')
    const openaiConfig = createOpenAIConfig()
    const openaiClient = new OpenAIClient(openaiConfig)
    await openaiClient.initialize()
    const embeddingService = new EmbeddingService(openaiClient)

    const pineconeConfig = createPineconeConfig()
    const pineconeClient = new PineconeClient(pineconeConfig)
    const pineconeService = new PineconeService(pineconeClient)

    console.log('âœ… ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ')

    // í˜„ìž¬ ë²¡í„° ê°œìˆ˜ í™•ì¸
    const status = await pineconeClient.checkConnection()
    console.log(`ðŸ“Š í˜„ìž¬ ë²¡í„° ê°œìˆ˜: ${status.vectorCount}`)

    // í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ë“¤
    const testQuestions = [
      'í˜¸ë‘ëŠ” ë­˜ ì¢‹ì•„í•˜ë‚˜ìš”?',
      'í˜¸ë‘',
      'ì¢‹ì•„í•˜ëŠ” ê²ƒ',
      'ì‚°ì±…',
      'ì—¬ìž',
      'ë‚˜ì´',
      'ìœ„ë¡œëŠ” ë­˜ ì¢‹ì•„í•˜ë‚˜ìš”?'
    ]

    for (const question of testQuestions) {
      console.log(`\nðŸ” ì§ˆë¬¸: "${question}"`)
      
      // ìž„ë² ë”© ìƒì„±
      const embeddingResult = await embeddingService.createEmbedding(question)
      console.log(`ìž„ë² ë”© ìƒì„± ì™„ë£Œ: ${embeddingResult.tokenCount} í† í°`)

      // ìž„ê³„ê°’ ì—†ì´ ê²€ìƒ‰ (TOP_K=5)
      const searchResults = await pineconeService.query(
        embeddingResult.embedding,
        {
          topK: 5,
          scoreThreshold: 0.0 // ìž„ê³„ê°’ ì œê±°
        }
      )

      if (searchResults.length > 0) {
        console.log(`ðŸ“‹ ê²€ìƒ‰ ê²°ê³¼: ${searchResults.length}ê°œ`)
        searchResults.forEach((result, index) => {
          console.log(`  ${index + 1}. ID: ${result.id}`)
          console.log(`     ì œëª©: "${result.metadata.title}"`)
          console.log(`     ìœ ì‚¬ë„: ${result.score.toFixed(4)}`)
          console.log(`     ë‚´ìš©: ${result.metadata.content.substring(0, 50)}...`)
        })
        
        // ê¸°ì¡´ ìž„ê³„ê°’(0.7)ê³¼ ë¹„êµ
        const highScoreResults = searchResults.filter(r => r.score >= 0.7)
        console.log(`ðŸ“Š ìž„ê³„ê°’ 0.7 ì´ìƒ: ${highScoreResults.length}ê°œ`)
        
        const mediumScoreResults = searchResults.filter(r => r.score >= 0.5 && r.score < 0.7)
        console.log(`ðŸ“Š ìž„ê³„ê°’ 0.5-0.7: ${mediumScoreResults.length}ê°œ`)
        
      } else {
        console.log('âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ')
      }
    }

    console.log('\nðŸŽ‰ ë²¡í„° ê²€ìƒ‰ ë””ë²„ê¹… ì™„ë£Œ!')

  } catch (error) {
    console.error('\nâŒ ë””ë²„ê¹… ì‹¤íŒ¨:', error)
    process.exit(1)
  }
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
if (require.main === module) {
  debugVectorSearch()
}