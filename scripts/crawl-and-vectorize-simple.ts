#!/usr/bin/env tsx

/**
 * HTML í¬ë¡¤ë§ + ë²¡í„°í™” ë‹¨ìˆœ ìŠ¤í¬ë¦½íŠ¸ (MVP)
 * 
 * ì§€ì •ëœ ì›¹ì‚¬ì´íŠ¸ë¥¼ í¬ë¡¤ë§í•˜ê³  ìë™ìœ¼ë¡œ ë²¡í„°í™”í•˜ì—¬ Pineconeì— ì €ì¥í•©ë‹ˆë‹¤.
 * 
 * ì‚¬ìš©ë²•: npm run crawl-and-vectorize <start-url> --env=<dev|test|prod> [ì˜µì…˜]
 */

import { HtmlCrawlerService } from '../src/services/html/html-crawler.service'
import { DocumentProcessor } from '../src/services/document/document.processor'
import { NotionService } from '../src/services/notion/notion.service'
import { EmbeddingService } from '../src/services/openai/embedding.service'
import { OpenAIClient } from '../src/services/openai/openai.client'
import { PineconeService } from '../src/services/vector/pinecone.service'
import { PineconeClient } from '../src/services/vector/pinecone.client'
import { createNotionConfig } from '../src/config/notion'
import { createOpenAIConfig } from '../src/config/openai'
import { createPineconeConfig } from '../src/config/pinecone'
import type { CrawlOptions } from '../src/types/html'
import { parseEnvironment, loadEnvironment, getEnvironmentHelp } from './utils/env-loader'

interface CliOptions extends Partial<CrawlOptions> {
  verbose?: boolean
  dryRun?: boolean
}

function parseArgs(): { startUrl: string; options: CliOptions } {
  const args = process.argv.slice(2)
  
  if (args.length === 0 || args.includes('--help') || args.includes('-h')) {
    console.log(`
ğŸ•·ï¸ HTML í¬ë¡¤ë§ + ë²¡í„°í™” ë„êµ¬ (MVP)

ì‚¬ìš©ë²•:
  npm run crawl-and-vectorize -- <start-url> --env=<dev|test|prod> [ì˜µì…˜]

í•„ìˆ˜ ì¸ì:
  <start-url>       ì‹œì‘ URL (ì˜ˆ: https://help.pro.sixshop.com/)

ì˜µì…˜:
  --max-pages <n>   ìµœëŒ€ í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸ê°’: 10)
  --max-depth <n>   ìµœëŒ€ í¬ë¡¤ë§ ê¹Šì´ (ê¸°ë³¸ê°’: 2)
  --no-vectorize    ë²¡í„°í™” ë¹„í™œì„±í™” (í¬ë¡¤ë§ë§Œ ì‹¤í–‰)
  --verbose         ìƒì„¸ ë¡œê·¸ ì¶œë ¥
  --dry-run         ì‹¤ì œ ì €ì¥ ì—†ì´ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
  --help, -h        ë„ì›€ë§ í‘œì‹œ
${getEnvironmentHelp()}

âš ï¸  ì¤‘ìš”: npm run ëª…ë ¹ì–´ ì‚¬ìš© ì‹œ ë°˜ë“œì‹œ -- êµ¬ë¶„ìë¥¼ ì‚¬ìš©í•˜ì„¸ìš”

ì˜ˆì‹œ:
  npm run crawl-and-vectorize -- https://help.pro.sixshop.com/ --env=dev --max-pages=20
  npm run crawl-and-vectorize -- https://help.pro.sixshop.com/ --env=prod --no-vectorize
  npm run crawl-and-vectorize -- https://help.pro.sixshop.com/ --env=prod --dry-run

ì§ì ‘ ì‹¤í–‰ (tsx):
  tsx scripts/crawl-and-vectorize-simple.ts https://help.pro.sixshop.com/ --env=prod --max-pages=20
`)
    process.exit(0)
  }

  const startUrl = args.find(arg => arg.startsWith('http'))
  if (!startUrl) {
    console.error('âŒ ì‹œì‘ URLì´ í•„ìš”í•©ë‹ˆë‹¤.')
    process.exit(1)
  }

  const options: CliOptions = {
    maxPages: 10,
    maxDepth: 2,
    autoVectorize: true
  }

  // ì˜µì…˜ íŒŒì‹±
  args.forEach((arg, index) => {
    if (arg === '--max-pages' && args[index + 1]) {
      options.maxPages = parseInt(args[index + 1])
    }
    if (arg === '--max-depth' && args[index + 1]) {
      options.maxDepth = parseInt(args[index + 1])
    }
    if (arg === '--no-vectorize') {
      options.autoVectorize = false
    }
    if (arg === '--verbose') {
      options.verbose = true
    }
    if (arg === '--dry-run') {
      options.dryRun = true
    }
  })

  return { startUrl, options }
}

// ë“œë¼ì´ëŸ° ëª¨ë“œìš© Mock ì„œë¹„ìŠ¤
function createMockPineconeService(): PineconeService {
  const mockClient = {
    getIndex: () => ({
      upsert: async (data: any) => {
        console.log(`   [DRY-RUN] ë²¡í„° ì €ì¥ ì‹œë®¬ë ˆì´ì…˜: ${data[0]?.id}`)
      }
    })
  } as any

  return new PineconeService(mockClient)
}

async function main() {
  const startTime = Date.now()
  
  // í™˜ê²½ ì„¤ì •ì„ ë¨¼ì € ë¡œë“œ (URL íŒŒì‹± ì „ì—)
  const environment = parseEnvironment(process.argv.slice(2))
  loadEnvironment(environment)
  
  const { startUrl, options } = parseArgs()

  console.log('ğŸš€ HTML í¬ë¡¤ë§ + ë²¡í„°í™” ì‹œì‘')
  console.log(`ğŸ”— ì‹œì‘ URL: ${startUrl}`)
  console.log(`âš™ï¸  ì˜µì…˜:`)
  console.log(`   ìµœëŒ€ í˜ì´ì§€: ${options.maxPages}ê°œ`)
  console.log(`   ìµœëŒ€ ê¹Šì´: ${options.maxDepth}`)
  console.log(`   ìë™ ë²¡í„°í™”: ${options.autoVectorize ? 'ì˜ˆ' : 'ì•„ë‹ˆì˜¤'}`)
  console.log(`   ë“œë¼ì´ëŸ° ëª¨ë“œ: ${options.dryRun ? 'ì˜ˆ' : 'ì•„ë‹ˆì˜¤'}`)
  console.log('')

  try {
    // ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    const notionConfig = createNotionConfig()
    const openaiConfig = createOpenAIConfig()
    const pineconeConfig = createPineconeConfig()

    const notionService = new NotionService(notionConfig)
    const openaiClient = new OpenAIClient(openaiConfig)
    const embeddingService = new EmbeddingService(openaiClient)
    const pineconeClient = new PineconeClient(pineconeConfig)
    const pineconeService = new PineconeService(pineconeClient)

    // NotionServiceëŠ” ë²¡í„°í™”ì—ë§Œ í•„ìš”í•˜ë¯€ë¡œ autoVectorizeê°€ trueì¼ ë•Œë§Œ ì´ˆê¸°í™”
    if (options.autoVectorize && !options.dryRun) {
      await notionService.initialize()
    }
    
    if (options.verbose) {
      console.log('âœ… ëª¨ë“  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ\n')
    }

    // DocumentProcessor ë° HtmlCrawlerService ì´ˆê¸°í™”
    let documentProcessor: DocumentProcessor | undefined
    if (options.autoVectorize) {
      documentProcessor = new DocumentProcessor(
        notionService,
        embeddingService,
        options.dryRun ? createMockPineconeService() : pineconeService
      )
    }

    const crawler = new HtmlCrawlerService(documentProcessor)

    // í¬ë¡¤ë§ + ë²¡í„°í™” ì‹¤í–‰
    console.log('ğŸ•·ï¸ í¬ë¡¤ë§ ì‹œì‘...')
    const session = await crawler.crawlSite(startUrl, {
      maxPages: options.maxPages,
      maxDepth: options.maxDepth,
      autoVectorize: options.autoVectorize,
      crawlDelay: 2000,  // ì„œë²„ ë¶€í•˜ ë°©ì§€
      concurrency: 2     // ë™ì‹œ ìš”ì²­ ì œí•œ
    })

    // ê²°ê³¼ ì¶œë ¥
    const elapsed = ((Date.now() - startTime) / 1000).toFixed(1)
    
    console.log('')
    console.log('ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!')
    console.log(`â±ï¸  ì†Œìš” ì‹œê°„: ${elapsed}ì´ˆ`)
    console.log(`ğŸ“Š í¬ë¡¤ë§ ê²°ê³¼:`)
    console.log(`   ì²˜ë¦¬ëœ í˜ì´ì§€: ${session.statistics.processedPages}ê°œ`)
    console.log(`   ê±´ë„ˆë›´ í˜ì´ì§€: ${session.statistics.skippedPages}ê°œ`)
    console.log(`   ì¤‘ë³µ í˜ì´ì§€: ${session.statistics.duplicatePages}ê°œ`)
    console.log(`   ì—ëŸ¬ í˜ì´ì§€: ${session.statistics.errorPages}ê°œ`)

    if (session.vectorizationResult && options.autoVectorize) {
      console.log(`ğŸ“Š ë²¡í„°í™” ê²°ê³¼:`)
      console.log(`   ì„±ê³µ: ${session.vectorizationResult.processed}ê°œ`)
      console.log(`   ì‹¤íŒ¨: ${session.vectorizationResult.failed}ê°œ`)
      
      if (session.vectorizationResult.errors.length > 0) {
        console.log(`âŒ ë²¡í„°í™” ì‹¤íŒ¨ ëª©ë¡:`)
        session.vectorizationResult.errors.forEach(error => {
          console.log(`   - ${error.title}: ${error.error}`)
        })
      }
    }

  } catch (error) {
    console.error('âŒ ì‹¤í–‰ ì‹¤íŒ¨:', error)
    process.exit(1)
  }
}

if (require.main === module) {
  main().catch(console.error)
}